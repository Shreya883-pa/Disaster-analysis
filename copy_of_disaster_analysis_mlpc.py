# -*- coding: utf-8 -*-
"""Copy of disaster_analysis_MLPC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-_SmuOjm9vw4R-YZCn1wcClLjW-EfSJd
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline
from joblib import Parallel, delayed
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier


import re
import string

df = pd.read_csv("/disaster_data_set.csv", encoding='latin1')



print("Dataset shape:", df.shape)
print("\nColumns:", df.columns)
print("\nSample Data:")
print(df.head())

def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)  # remove URLs
    text = re.sub(r'[^a-z\s]', '', text)  # remove punctuation and numbers
    return re.sub(r'\s+', ' ', text).strip()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Print available columns to debug
print(df.columns)

# Update numeric_columns based on available columns
numeric_columns = [
    'Total Deaths', 'No. Injured', 'No. Affected', 'No. Homeless',
    'Total Affected', "Reconstruction Costs ('000 US$')",
    "Total Damage ('000 US$')", "Total Damage, Adjusted ('000 US$')",
    "Insured Damage ('000 US$')", "Insured Damage, Adjusted ('000 US$')",
    "AID Contribution ('000 US$')", 'Magnitude', 'Latitude', 'Longitude'
]

# Filter numeric_columns to only include columns that exist in df
existing_numeric_columns = [col for col in numeric_columns if col in df.columns]

# Convert existing columns to numeric
for col in existing_numeric_columns:
    df[col] = pd.to_numeric(
        df[col].astype(str).str.replace(',', '').str.strip(),
        errors='coerce'
    )

# Correlation heatmap (only for existing columns)
if existing_numeric_columns:
    plt.figure(figsize=(12, 8))
    corr = df[existing_numeric_columns].corr()
    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
    plt.title('Correlation Heatmap of Disaster Impact Features')
    plt.show()
else:
    print("No numeric columns found for correlation heatmap.")

"""
sns.pairplot(df[['age', 'bmi', 'bp', 's1', 'target']])
plt.suptitle('Pairplot of Selected Features', y=1.02)
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(df['target'], kde=True)
plt.title('Distribution of Target Variable')
plt.xlabel('Diabetes Progression')
plt.show()
"""
# Define the column to plot
column_to_plot = 'Total Deaths'

# Check if the column exists and create histogram
if column_to_plot in df.columns:
    # Filter out NaN and non-positive values for better visualization
    data = df[column_to_plot].dropna().where(lambda x: x > 0).dropna()

    if len(data) > 0:
        plt.figure(figsize=(8, 5))
        sns.histplot(x=data, kde=True, bins=30)  # Pass Series directly to x
        plt.title(f'Distribution of {column_to_plot}')
        plt.xlabel(column_to_plot)
        plt.ylabel('Count')
        plt.show()
    else:
        print(f"No valid data (non-zero and non-NaN) found in '{column_to_plot}' for histogram.")
else:
    print(f"Column '{column_to_plot}' not found in DataFrame. Available columns: {df.columns.tolist()}")

# Optional: Print summary statistics to diagnose the issue
print(f"Summary of {column_to_plot}:")
print(df[column_to_plot].describe())

texts = df['Event Name'].astype(str).tolist()
cleaned_texts = Parallel(n_jobs=-1)(delayed(clean_text)(text) for text in texts)
df['clean_text'] = cleaned_texts

x = df['clean_text']
y = df['Disaster Type']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('clf', LogisticRegression(max_iter=200))
])

X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression())
])
pipeline.fit(X_train, y_train)

# Make predictions
y_pred = pipeline.predict(X_test)

# Print evaluation metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nAccuracy: {:.2f}%".format(accuracy_score(y_test, y_pred) * 100))

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

y_pred = pipeline.predict(X_test)  # Ensure this line is executed earlier

# Plot the predicted values
plt.plot(y_pred, 'bo')  # 'bo' creates blue dots for each prediction
plt.xlabel('Predicted')
plt.ylabel('Value')  # Add a y-label for clarity
plt.title('Predicted Values')  # Optional: Add a title
plt.show()

# Plot actual vs. predicted values
plt.scatter(y_pred, y_test, color='blue', alpha=0.5)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Actual vs Predicted Values')
plt.show()

pipeline.fit(X_train, y_train)

# Make predictions
y_pred = pipeline.predict(X_test)

# Print results
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nAccuracy: {:.2f}%".format(accuracy_score(y_test, y_pred) * 100))

# Create sample data
data = pd.DataFrame({
    'text': ['sample text 1', 'sample text 2', 'sample text 3', 'sample text 4'],
    'label': [0, 1, 0, 1]
})

# Define features (X) and target (y)
X = data['text']  # Features (e.g., text data)
y = data['label']  # Target variable

# Convert text data to numerical features (if working with text)
vectorizer = TfidfVectorizer()
X_vec = vectorizer.fit_transform(X)

# Initialize and train the Linear Regression model
linreg_model = LinearRegression()
start = time.time()
linreg_model.fit(X_train_vec, y_train)
print("Linear Regression training completed in %.2f seconds." % (time.time() - start))

# Make predictions
y_pred = linreg_model.predict(X_test_vec)

# Plot actual vs. predicted values
plt.scatter(y_test, y_pred, color='blue', alpha=0.5)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

# Initialize and train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
start = time.time()
rf_model.fit(X_train_vec, y_train)
print("Random Forest training completed in %.2f seconds." % (time.time() - start))

# Make predictions
y_pred = rf_model.predict(X_test_vec)

# Print evaluation metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nAccuracy: {:.2f}%".format(accuracy_score(y_test, y_pred) * 100))

# Plot actual vs. predicted values
plt.scatter(y_test, y_pred, color='blue', alpha=0.5)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

print("\nSummary:")
print("- Random Forest captures complex patterns but may overfit on sparse data.")
print("- Linear Regression is not ideal for classification but added here for comparative insight (outputs rounded to class labels).")

